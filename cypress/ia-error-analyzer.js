require('dotenv').config();
const fetch = (...args) =>
  import('node-fetch').then(({ default: fetch }) => fetch(...args)); // Compat√≠vel com ESModules no Node.js

const OPENROUTER_API_URL = process.env.OPENROUTER_API_URL;
const MODEL_NAME = 'meta-llama/llama-4-maverick:free';

async function analyzeWithIA(logDeErro) {
  const prompt = `
Voc√™ √© um especialista em QA. Analise o seguinte erro de teste automatizado:

"${logDeErro}"

Responda com:
1. üìå **Motivo prov√°vel da falha**
2. ‚úÖ **Sugest√£o de corre√ß√£o**
`;

  try {
    const response = await fetch(OPENROUTER_API_URL, {
      method: 'POST',
      headers: {
        Authorization: `Bearer ${process.env.OPENROUTER_API_KEY}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: MODEL_NAME,
        messages: [{ role: 'user', content: prompt }],
        temperature: 0.3,
        max_tokens: 300
      })
    });

    const data = await response.json();
    return data.choices?.[0]?.message?.content || '‚ùå Erro: resposta da IA vazia.';
  } catch (error) {
    return `‚ùå Erro ao se comunicar com a IA: ${error.message}`;
  }
}

module.exports = { analyzeWithIA };
